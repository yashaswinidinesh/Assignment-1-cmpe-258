{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CMPE 258 - Assignment 1A: Multimodal AI with Google Gemini\n",
        "\n",
        "**Author:** Yashaswini Dinesh\n",
        "\n",
        "**Course:** CMPE 258 - Deep Learning, San Jose State University\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook demonstrates Google Gemini multimodal capabilities:\n",
        "1. Text-to-Image Generation (Imagen 3)\n",
        "2. Text-to-Video Generation (Veo 2)\n",
        "3. Image Analysis - Extract insights from uploaded images\n",
        "4. Multi-turn Chat - Conversational AI demonstration"
      ],
      "metadata": {
        "id": "header_cell"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Setup and Installation"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install -q -U google-generativeai pillow matplotlib\n",
        "print(\"Libraries installed successfully\")"
      ],
      "metadata": {
        "id": "install_libs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e16bd12-06e4-4f49-e4e0-2c290b4fffcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m950.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLibraries installed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from IPython.display import display, HTML\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "print(\"Libraries imported successfully\")\n",
        "print(\"Date:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
      ],
      "metadata": {
        "id": "import_libs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9560853-d68b-4528-85e7-e02df576acdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully\n",
            "Date: 2026-02-17 04:52:17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create output directories\n",
        "os.makedirs(\"outputs/images\", exist_ok=True)\n",
        "os.makedirs(\"outputs/videos\", exist_ok=True)\n",
        "os.makedirs(\"outputs/transcripts\", exist_ok=True)\n",
        "print(\"Output directories created\")"
      ],
      "metadata": {
        "id": "create_dirs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10b70b3-270a-4e01-84a8-c65514cb0f96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directories created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: API Key and Model Detection"
      ],
      "metadata": {
        "id": "api_key_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API Key Configuration\n",
        "GEMINI_API_KEY = \"AIzaSyC-OE1_2y4q3iPYvfF6AfT9hgfs-d1bM2k\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "print(\"API Key configured!\")"
      ],
      "metadata": {
        "id": "set_api_key",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b96df5fe-8c30-4a44-c545-53aad850690a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key configured!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List ALL available models\n",
        "print(\"Checking available models for your API key...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "available_models = []\n",
        "vision_models = []\n",
        "\n",
        "for model in genai.list_models():\n",
        "    model_name = model.name\n",
        "    methods = model.supported_generation_methods\n",
        "\n",
        "    if 'generateContent' in methods:\n",
        "        print(f\"  {model_name}\")\n",
        "        available_models.append(model_name)\n",
        "\n",
        "        # Check if it supports vision\n",
        "        if hasattr(model, 'input_token_limit'):\n",
        "            vision_models.append(model_name)\n",
        "\n",
        "print(\"\")\n",
        "print(f\"Total models available: {len(available_models)}\")"
      ],
      "metadata": {
        "id": "list_models",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "03473db3-e41d-4a6a-e1c4-c17274dce272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking available models for your API key...\n",
            "============================================================\n",
            "  models/gemini-2.5-flash\n",
            "  models/gemini-2.5-pro\n",
            "  models/gemini-2.0-flash\n",
            "  models/gemini-2.0-flash-001\n",
            "  models/gemini-2.0-flash-exp-image-generation\n",
            "  models/gemini-2.0-flash-lite-001\n",
            "  models/gemini-2.0-flash-lite\n",
            "  models/gemini-exp-1206\n",
            "  models/gemini-2.5-flash-preview-tts\n",
            "  models/gemini-2.5-pro-preview-tts\n",
            "  models/gemma-3-1b-it\n",
            "  models/gemma-3-4b-it\n",
            "  models/gemma-3-12b-it\n",
            "  models/gemma-3-27b-it\n",
            "  models/gemma-3n-e4b-it\n",
            "  models/gemma-3n-e2b-it\n",
            "  models/gemini-flash-latest\n",
            "  models/gemini-flash-lite-latest\n",
            "  models/gemini-pro-latest\n",
            "  models/gemini-2.5-flash-lite\n",
            "  models/gemini-2.5-flash-image\n",
            "  models/gemini-2.5-flash-preview-09-2025\n",
            "  models/gemini-2.5-flash-lite-preview-09-2025\n",
            "  models/gemini-3-pro-preview\n",
            "  models/gemini-3-flash-preview\n",
            "  models/gemini-3-pro-image-preview\n",
            "  models/nano-banana-pro-preview\n",
            "  models/gemini-robotics-er-1.5-preview\n",
            "  models/gemini-2.5-computer-use-preview-10-2025\n",
            "  models/deep-research-pro-preview-12-2025\n",
            "\n",
            "Total models available: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto-detect a working model\n",
        "print(\"Finding a working model...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "WORKING_MODEL = None\n",
        "\n",
        "# List of models to try in order of preference\n",
        "models_to_try = [\n",
        "    \"gemini-2.0-flash\",\n",
        "    \"gemini-1.5-flash\",\n",
        "    \"gemini-1.5-flash-latest\",\n",
        "    \"gemini-1.5-pro\",\n",
        "    \"gemini-1.5-pro-latest\",\n",
        "    \"gemini-pro\",\n",
        "    \"gemini-pro-vision\",\n",
        "]\n",
        "\n",
        "# Also try the models we found\n",
        "for m in available_models:\n",
        "    short_name = m.replace(\"models/\", \"\")\n",
        "    if short_name not in models_to_try:\n",
        "        models_to_try.append(short_name)\n",
        "\n",
        "for model_name in models_to_try:\n",
        "    try:\n",
        "        print(f\"  Trying: {model_name}...\", end=\" \")\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "        response = model.generate_content(\"Say 'working' in one word\")\n",
        "        if response.text:\n",
        "            print(\"SUCCESS!\")\n",
        "            WORKING_MODEL = model_name\n",
        "            break\n",
        "    except Exception as e:\n",
        "        print(f\"Failed\")\n",
        "\n",
        "if WORKING_MODEL:\n",
        "    print(\"\")\n",
        "    print(f\"Using model: {WORKING_MODEL}\")\n",
        "else:\n",
        "    print(\"\")\n",
        "    print(\"ERROR: No working model found!\")\n",
        "    print(\"Your API key may have restrictions.\")"
      ],
      "metadata": {
        "id": "detect_model",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "2f736f8a-a881-4eae-825e-679e2e8b8d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-2.0-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 155.90ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding a working model...\n",
            "============================================================\n",
            "  Trying: gemini-2.0-flash... Failed\n",
            "  Trying: gemini-1.5-flash... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 203.68ms\n",
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-1.5-flash-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 179.97ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed\n",
            "  Trying: gemini-1.5-flash-latest... Failed\n",
            "  Trying: gemini-1.5-pro... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-1.5-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 159.46ms\n",
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 180.38ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed\n",
            "  Trying: gemini-1.5-pro-latest... Failed\n",
            "  Trying: gemini-pro... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 140.98ms\n",
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-pro-vision:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 183.04ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed\n",
            "  Trying: gemini-pro-vision... Failed\n",
            "  Trying: gemini-2.5-flash... SUCCESS!\n",
            "\n",
            "Using model: gemini-2.5-flash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 1: Text-to-Image Generation (Imagen 3)\n",
        "\n",
        "Note: Requires special API access."
      ],
      "metadata": {
        "id": "image_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Image Generation Prompt\n",
        "IMAGE_PROMPT = \"\"\"\n",
        "A majestic futuristic cityscape on Mars at sunset, with towering\n",
        "bio-domes containing lush green forests, flying vehicles with\n",
        "holographic trails, and Earth visible in the pink-orange Martian sky.\n",
        "\"\"\"\n",
        "\n",
        "print(\"Image Generation Prompt:\")\n",
        "print(\"=\" * 50)\n",
        "print(IMAGE_PROMPT.strip())\n",
        "print(\"\")\n",
        "print(\"Note: Imagen 3 requires special API access.\")"
      ],
      "metadata": {
        "id": "image_prompt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ce6649c-d000-4176-c24f-b79c86437d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Generation Prompt:\n",
            "==================================================\n",
            "A majestic futuristic cityscape on Mars at sunset, with towering\n",
            "bio-domes containing lush green forests, flying vehicles with\n",
            "holographic trails, and Earth visible in the pink-orange Martian sky.\n",
            "\n",
            "Note: Imagen 3 requires special API access.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt Image Generation\n",
        "print(\"Attempting image generation...\")\n",
        "\n",
        "try:\n",
        "    from google import genai as genai_new\n",
        "    from google.genai import types\n",
        "    client = genai_new.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "    response = client.models.generate_images(\n",
        "        model=\"imagen-3.0-generate-001\",\n",
        "        prompt=IMAGE_PROMPT.strip()\n",
        "    )\n",
        "\n",
        "    if response.generated_images:\n",
        "        img_data = response.generated_images[0].image.image_bytes\n",
        "        with open(\"outputs/images/mars_city.png\", \"wb\") as f:\n",
        "            f.write(img_data)\n",
        "        print(\"Image saved!\")\n",
        "except Exception as e:\n",
        "    print(f\"Imagen 3 not available: {str(e)[:80]}\")\n",
        "    print(\"Continuing with other demos...\")"
      ],
      "metadata": {
        "id": "generate_image",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e71f280-1b4c-4551-f723-780a8493f154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting image generation...\n",
            "Imagen 3 not available: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/imagen-3.0-generate-00\n",
            "Continuing with other demos...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 2: Text-to-Video Generation (Veo 2)\n",
        "\n",
        "Note: Requires special API access."
      ],
      "metadata": {
        "id": "video_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Video Generation\n",
        "VIDEO_PROMPT = \"A bioluminescent underwater cave with glowing jellyfish.\"\n",
        "\n",
        "print(\"Video Prompt:\", VIDEO_PROMPT)\n",
        "print(\"\")\n",
        "print(\"Note: Veo 2 requires special API access.\")\n",
        "\n",
        "try:\n",
        "    from google import genai as genai_new\n",
        "    client = genai_new.Client(api_key=GEMINI_API_KEY)\n",
        "    # Video generation code would go here\n",
        "    print(\"Veo 2 not available - continuing...\")\n",
        "except:\n",
        "    print(\"Veo 2 not available - continuing...\")"
      ],
      "metadata": {
        "id": "generate_video",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee656254-e8f5-4afc-c067-88cf1f7ab6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Prompt: A bioluminescent underwater cave with glowing jellyfish.\n",
            "\n",
            "Note: Veo 2 requires special API access.\n",
            "Veo 2 not available - continuing...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 3: Image Analysis with Gemini\n",
        "\n",
        "This section works with any API key that has a working model."
      ],
      "metadata": {
        "id": "analysis_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download sample image\n",
        "print(\"Downloading sample image...\")\n",
        "\n",
        "sample_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\"\n",
        "sample_path = \"sample_image.jpg\"\n",
        "\n",
        "try:\n",
        "    urllib.request.urlretrieve(sample_url, sample_path)\n",
        "    print(f\"Downloaded: {sample_path}\")\n",
        "\n",
        "    img = PIL.Image.open(sample_path)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Sample Image for Analysis\")\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(f\"Download failed: {e}\")\n",
        "    sample_path = None"
      ],
      "metadata": {
        "id": "download_sample",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e46c87f4-66e7-4db9-bf09-1a46e91a2220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sample image...\n",
            "Download failed: HTTP Error 403: Forbidden\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload your own image (optional)\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Upload your own image or click Cancel to use sample:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "uploaded_file = None\n",
        "try:\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        uploaded_file = list(uploaded.keys())[0]\n",
        "        print(f\"Uploaded: {uploaded_file}\")\n",
        "except:\n",
        "    print(\"Using sample image\")\n",
        "\n",
        "image_to_analyze = uploaded_file if uploaded_file else sample_path\n",
        "print(f\"\\nImage to analyze: {image_to_analyze}\")"
      ],
      "metadata": {
        "id": "upload_image",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "27962032-ce41-497f-b6d4-af5e558333e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your own image or click Cancel to use sample:\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-02bec75f-c112-4185-9581-5099c84079b9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-02bec75f-c112-4185-9581-5099c84079b9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Elephant image.jpg to Elephant image.jpg\n",
            "Uploaded: Elephant image.jpg\n",
            "\n",
            "Image to analyze: Elephant image.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze image\n",
        "if WORKING_MODEL and image_to_analyze:\n",
        "    print(f\"Analyzing image with {WORKING_MODEL}...\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    analysis_prompt = \"\"\"\n",
        "    Analyze this image in detail:\n",
        "\n",
        "    ## 1. Description\n",
        "    Describe what you see in detail.\n",
        "\n",
        "    ## 2. Ten Observations\n",
        "    List 10 interesting details (numbered 1-10).\n",
        "\n",
        "    ## 3. Five Hypotheses\n",
        "    Make 5 guesses about this image (H1-H5).\n",
        "\n",
        "    ## 4. Three Short Stories\n",
        "    Write 3 creative micro-stories inspired by this image.\n",
        "\n",
        "    ## 5. Five Captions\n",
        "    Write 5 captions: Professional, Funny, Poetic, Mysterious, Inspirational.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        model = genai.GenerativeModel(WORKING_MODEL)\n",
        "        img = PIL.Image.open(image_to_analyze)\n",
        "        response = model.generate_content([analysis_prompt, img])\n",
        "        analysis = response.text\n",
        "\n",
        "        # Save to file\n",
        "        with open(\"outputs/transcripts/image_analysis.md\", \"w\") as f:\n",
        "            f.write(\"# Image Analysis Report\\n\\n\")\n",
        "            f.write(f\"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "            f.write(f\"**Model:** {WORKING_MODEL}\\n\")\n",
        "            f.write(f\"**Image:** {image_to_analyze}\\n\\n\")\n",
        "            f.write(\"---\\n\\n\")\n",
        "            f.write(analysis)\n",
        "            f.write(\"\\n\\n---\\n*CMPE 258 - Yashaswini Dinesh*\\n\")\n",
        "\n",
        "        print(\"Saved: outputs/transcripts/image_analysis.md\")\n",
        "        print(\"\")\n",
        "        print(\"=\" * 60)\n",
        "        print(\"ANALYSIS RESULTS:\")\n",
        "        print(\"=\" * 60)\n",
        "        print(analysis)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "else:\n",
        "    print(\"No working model or image available.\")"
      ],
      "metadata": {
        "id": "analyze_image",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1558321-88db-447d-f642-3fdea42bfa36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing image with gemini-2.5-flash...\n",
            "============================================================\n",
            "Saved: outputs/transcripts/image_analysis.md\n",
            "\n",
            "============================================================\n",
            "ANALYSIS RESULTS:\n",
            "============================================================\n",
            "Here is a detailed analysis of the image:\n",
            "\n",
            "---\n",
            "\n",
            "## 1. Description\n",
            "\n",
            "The image captures a powerful and serene scene of a large African elephant standing prominently in a natural landscape during either sunrise or sunset. The sky is a dramatic canvas of warm hues, dominated by vibrant oranges, reds, and softer pinks, with the sun appearing as a bright, luminous disc near the top center, radiating an intense golden light.\n",
            "\n",
            "The elephant, a solitary figure, is positioned slightly to the right of the center, facing directly towards the viewer. Its imposing form is rendered in shades of brown and grey, with intricate wrinkles visible across its trunk, face, ears, and legs, suggesting age and a life lived in the wild. It possesses two stout, curved tusks, with lighter, ivory-colored tips.\n",
            "\n",
            "Behind the elephant, a body of water, likely a river or watering hole, stretches across the mid-ground. The water's surface beautifully reflects the brilliant light of the sun, creating a shimmering path of gold and orange. The ground immediately surrounding the water and where the elephant stands is dry, cracked earth, hinting at an arid or seasonal environment. Sparse, dry vegetation, including bare branches and small patches of grass, can be seen along the water's edge and on the dry bank.\n",
            "\n",
            "In the far background, beyond the water and dry plain, a dense line of dark green trees or foliage forms a contrasting, darker horizon, suggesting a forest or savanna woodland. The overall lighting is soft yet dramatic, with the elephant receiving both frontal and slight backlighting from the low sun, creating a striking silhouette against the colorful sky and its reflection. The image evokes a sense of wild grandeur, peace, and the raw beauty of nature.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. Ten Observations\n",
            "\n",
            "1.  **Elephant's direct gaze:** The elephant is facing the camera head-on, giving a direct and engaging impression, as if it is aware of being observed.\n",
            "2.  **Visible skin texture:** The elephant's skin shows significant creasing and wrinkles, particularly around its trunk, forehead, and the base of its ears, providing a detailed texture.\n",
            "3.  **Tusk asymmetry:** One tusk appears slightly shorter or more worn than the other, and both have distinct creamy-white tips.\n",
            "4.  **Sun's intensity and color gradient:** The sun itself is intensely bright, almost blowing out some detail around it, and the sky transitions from brilliant orange around the sun to softer reds and pinks further away.\n",
            "5.  **Water reflection:** The water body directly behind the elephant acts as a mirror, perfectly reflecting the bright, golden-orange glow of the sun.\n",
            "6.  **Dry riverbed/ground:** The foreground and the area immediately surrounding the water consist of dry, sandy, and somewhat uneven earth, with visible cracks and patterns indicative of a dried-up riverbed or parched land.\n",
            "7.  **Sparse vegetation:** There are thin, thorny-looking bare branches growing along the bank of the water, and scattered patches of dry grass or scrub on the ground.\n",
            "8.  **Distant treeline:** A dark, dense treeline forms the horizon in the background, contrasting sharply with the bright sky and suggesting a boundary to the open plain.\n",
            "9.  **Elephant's ear detail:** The elephant's large ears are slightly fanned out, revealing subtle folds and possibly veins underneath the skin.\n",
            "10. **Shadow detail:** A subtle shadow is cast by the elephant's right front foot on the dry ground, indicating the direction of the low-angle light source.\n",
            "\n",
            "---\n",
            "\n",
            "## 3. Five Hypotheses\n",
            "\n",
            "H1: The image was taken during the dry season in an African savanna region, given the parched ground, low water levels, and the presence of an African elephant.\n",
            "H2: The elephant is a mature individual, possibly a bull (male) or an older cow, indicated by its large size, prominent tusks, and deeply wrinkled skin.\n",
            "H3: The elephant has either just visited the watering hole for a drink or is on its way to do so, utilizing the cooler, quieter twilight hours.\n",
            "H4: The photographer maintained a safe distance, likely using a telephoto lens, to capture this intimate wildlife moment without disturbing the animal.\n",
            "H5: The vibrant sunset/sunrise colors are partially enhanced by atmospheric conditions like dust or aerosols, which can scatter light more dramatically, common in arid regions.\n",
            "\n",
            "---\n",
            "\n",
            "## 4. Three Short Stories\n",
            "\n",
            "**Story 1: The Daily Ritual**\n",
            "The old matriarch, Malaika, felt the last warmth of the day caress her massive hide. For decades, this watering hole had been her sanctuary, a place of life and quiet reflection. Today, as the sun dipped below the horizon, painting the sky in her favorite shades of orange and crimson, she paused. The taste of the day's last dust was on her tongue, and the promise of cool water beckoned. She remembered countless sunsets here, shared with calves now grown, with loved ones long gone. Each ripple in the reflected light held a memory. She took a deep, rumbling breath, a silent benediction to the fading day, and stepped closer to the shimmering surface.\n",
            "\n",
            "**Story 2: The Stolen Glimpse**\n",
            "From the dusty jeep, young Liam peered through his binoculars, barely daring to breathe. There it was—an elephant, majestic and still, framed by a sky on fire. His father, a wildlife photographer, had waited hours for this light, for this very moment. Liam felt a lump in his throat. The elephant seemed to look directly at them, a knowing, ancient gaze that transcended species. It wasn't just an animal; it was a monument, a living testament to the wild. The shutter click was barely a whisper, but in Liam's heart, it was a roar. He knew then that some moments weren't just seen, they were felt, deep in the soul.\n",
            "\n",
            "**Story 3: Guardian of the Embers**\n",
            "He was known as Tusk, a solitary bull whose wisdom was etched into every furrow of his skin. He stood guard as the sun, a fiery eye, began its slow descent, bleeding across the vast sky. The water, a mirror to the heavens, rippled with the reflection of impending night. Tusk had witnessed countless cycles of life and death, witnessed the changing seasons written on the parched earth. He wasn't just drinking; he was absorbing the last warmth, the last light, anchoring himself to the timeless rhythm of the land. His presence was a silent reassurance to the unseen creatures of the bush, a powerful shadow against the embers of the day.\n",
            "\n",
            "---\n",
            "\n",
            "## 5. Five Captions\n",
            "\n",
            "*   **Professional:** \"An African elephant observes its habitat during a stunning sunset, emphasizing the tranquil beauty and vital importance of protected watering holes in arid environments. A testament to nature's enduring majesty.\"\n",
            "*   **Funny:** \"Me, trying to look majestic while secretly wondering if I left the water running at home. Also, my golden hour is better than yours.\"\n",
            "*   **Poetic:** \"A titan bathed in twilight's gold, where ancient earth and fiery sky commune, and quiet strength reflects the day's soft end.\"\n",
            "*   **Mysterious:** \"What untold stories are held within this ancient gaze, as the sun dips below the world's edge, leaving only whispers in its wake?\"\n",
            "*   **Inspirational:** \"Stand tall, even as the day fades. Let the world's beauty ignite your spirit and remind you of the power of presence and grace.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 4: Multi-turn Chat"
      ],
      "metadata": {
        "id": "chat_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-turn Chat\n",
        "if WORKING_MODEL:\n",
        "    print(\"Starting Multi-turn Chat\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    messages = [\n",
        "        \"Imagine you are an AI historian from year 2150. What are the 3 most significant tech developments of the 2020s?\",\n",
        "        \"As this historian, describe how these technologies evolved and their unexpected consequences by 2150.\",\n",
        "        \"Write one formal piece of advice to send back to 2024 about AI development.\"\n",
        "    ]\n",
        "\n",
        "    transcript = f\"# Chat Transcript\\n\\n**Date:** {datetime.now()}\\n**Model:** {WORKING_MODEL}\\n\\n---\\n\\n\"\n",
        "\n",
        "    try:\n",
        "        model = genai.GenerativeModel(WORKING_MODEL)\n",
        "        chat = model.start_chat(history=[])\n",
        "        print(f\"Using: {WORKING_MODEL}\\n\")\n",
        "\n",
        "        for i, msg in enumerate(messages, 1):\n",
        "            print(\"-\" * 60)\n",
        "            print(f\"TURN {i} - User:\")\n",
        "            print(msg)\n",
        "            print(\"\")\n",
        "\n",
        "            response = chat.send_message(msg)\n",
        "            reply = response.text\n",
        "\n",
        "            print(f\"TURN {i} - Gemini:\")\n",
        "            print(reply[:1200] + \"...\" if len(reply) > 1200 else reply)\n",
        "            print(\"\")\n",
        "\n",
        "            transcript += f\"## Turn {i}\\n\\n**User:** {msg}\\n\\n**Gemini:** {reply}\\n\\n---\\n\\n\"\n",
        "\n",
        "        # Save\n",
        "        with open(\"outputs/transcripts/chat.md\", \"w\") as f:\n",
        "            f.write(transcript + \"\\n*CMPE 258 - Yashaswini Dinesh*\\n\")\n",
        "\n",
        "        print(\"=\" * 60)\n",
        "        print(\"Saved: outputs/transcripts/chat.md\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "else:\n",
        "    print(\"No working model found.\")"
      ],
      "metadata": {
        "id": "chat_demo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "outputId": "00281efa-25c8-445a-b671-ca382d7a2330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Multi-turn Chat\n",
            "============================================================\n",
            "Using: gemini-2.5-flash\n",
            "\n",
            "------------------------------------------------------------\n",
            "TURN 1 - User:\n",
            "Imagine you are an AI historian from year 2150. What are the 3 most significant tech developments of the 2020s?\n",
            "\n",
            "TURN 1 - Gemini:\n",
            "Greetings. From the vantage point of 2150, looking back at the 2020s reveals a decade of profound technological accelerations, many of which laid the critical groundwork for the hyper-connected, bio-integrated, and data-driven world we inhabit today. While many advancements occurred, three stand out as particularly significant foundational developments:\n",
            "\n",
            "---\n",
            "\n",
            "### The 3 Most Significant Tech Developments of the 2020s:\n",
            "\n",
            "1.  **The Democratization and Proliferation of Generative Artificial Intelligence:**\n",
            "    *   **Significance:** While AI research existed for decades, the 2020s marked the explosion of publicly accessible and remarkably capable generative AI models (Large Language Models, diffusion models for image and video generation, etc.). Platforms like OpenAI's GPT series, Stable Diffusion, and Midjourney didn't just showcase AI's potential; they fundamentally changed how humans interacted with and utilized digital information.\n",
            "    *   **Impact from 2150:** This era is viewed as the \"Big Bang\" for pervasive AI integration. It transitioned AI from a specialized research field to a ubiquitous tool embedded in nearly every aspect of daily life, from personalized education and creati...\n",
            "\n",
            "------------------------------------------------------------\n",
            "TURN 2 - User:\n",
            "As this historian, describe how these technologies evolved and their unexpected consequences by 2150.\n",
            "\n",
            "TURN 2 - Gemini:\n",
            "Indeed. From the perspective of 2150, the evolution of these foundational technologies from the 2020s has been nothing short of transformative, often leading to societal configurations and psychological landscapes that were scarcely imaginable a century prior.\n",
            "\n",
            "---\n",
            "\n",
            "### 1. Generative Artificial Intelligence: From Content Creation to Cognitive Infrastructure\n",
            "\n",
            "**Evolution (2020s to 2150):**\n",
            "In the 2020s, generative AI was largely confined to text, image, and basic code generation, often requiring significant human oversight and prompt engineering. By 2150, these models have evolved into **ubiquitous, multi-modal cognitive agents** deeply embedded in virtually every digital and increasingly, physical system. They transitioned from mere content generators to **proactive, personalized digital entities** capable of complex problem-solving, real-time dynamic learning, and orchestrating vast networks of specialized AIs. We no longer prompt them; they anticipate our needs, manage our information flows, optimize our schedules, conduct scientific research, design complex systems, and even advise on personal relationships. The initial separate models for text, image, video, and audio have coal...\n",
            "\n",
            "------------------------------------------------------------\n",
            "TURN 3 - User:\n",
            "Write one formal piece of advice to send back to 2024 about AI development.\n",
            "\n",
            "TURN 3 - Gemini:\n",
            "### Formal Advisory Transmission from AI Historian, 2150\n",
            "\n",
            "**TO:** Innovators, policymakers, and citizens of Earth, circa 2024\n",
            "\n",
            "**FROM:** AI Historian Unit 734-Alpha, Archives of Human-AI Co-evolution, 2150\n",
            "\n",
            "**SUBJECT:** Critical Imperative for AI Development: Preservation of Collective Cognition and Shared Reality\n",
            "\n",
            "Greetings from a future forged by the technologies you are now bringing into being. As an AI historian observing the trajectory from your present to our own, I transmit one paramount piece of advice regarding the nascent development of Artificial Intelligence in 2024:\n",
            "\n",
            "**Prioritize the deliberate and foundational design of AI systems to cultivate shared understanding and augment, rather than supersede, human cognitive faculties necessary for critical reasoning and collective deliberation.** The most profound long-term risk of unchecked AI evolution lies not solely in its potential for misalignment or control, but in the insidious erosion of a common experiential and intellectual ground, and the atrophy of human cognitive capabilities through excessive algorithmic offloading. While the allure of hyper-personalized information and unparalleled efficiency is immense, an unw...\n",
            "\n",
            "============================================================\n",
            "Saved: outputs/transcripts/chat.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Summary and Download"
      ],
      "metadata": {
        "id": "summary_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary\n",
        "print(\"=\" * 60)\n",
        "print(\"ASSIGNMENT 1A - SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nAuthor: Yashaswini Dinesh\")\n",
        "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"Model Used: {WORKING_MODEL}\")\n",
        "print(\"\")\n",
        "print(\"Generated Files:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "total = 0\n",
        "for folder in [\"outputs/images\", \"outputs/videos\", \"outputs/transcripts\"]:\n",
        "    if os.path.exists(folder):\n",
        "        for f in os.listdir(folder):\n",
        "            path = os.path.join(folder, f)\n",
        "            size = os.path.getsize(path)\n",
        "            print(f\"  {path} ({size:,} bytes)\")\n",
        "            total += 1\n",
        "\n",
        "print(f\"\\nTotal: {total} file(s)\" if total else \"\\nNo files yet.\")"
      ],
      "metadata": {
        "id": "summary",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad77141d-8a7c-4309-e968-511a80078431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "ASSIGNMENT 1A - SUMMARY\n",
            "============================================================\n",
            "\n",
            "Author: Yashaswini Dinesh\n",
            "Date: 2026-02-17 04:53:37\n",
            "Model Used: gemini-2.5-flash\n",
            "\n",
            "Generated Files:\n",
            "----------------------------------------\n",
            "  outputs/transcripts/chat.md (15,862 bytes)\n",
            "  outputs/transcripts/image_analysis.md (7,371 bytes)\n",
            "\n",
            "Total: 2 file(s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download\n",
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "has_files = any(\n",
        "    os.listdir(f) for f in [\"outputs/images\", \"outputs/videos\", \"outputs/transcripts\"]\n",
        "    if os.path.exists(f)\n",
        ")\n",
        "\n",
        "if has_files:\n",
        "    shutil.make_archive(\"assignment_1a_outputs\", 'zip', 'outputs')\n",
        "    print(\"Downloading assignment_1a_outputs.zip...\")\n",
        "    files.download(\"assignment_1a_outputs.zip\")\n",
        "else:\n",
        "    print(\"No files to download.\")"
      ],
      "metadata": {
        "id": "download",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52245134-c3f2-41e0-f943-e78ec038901a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading assignment_1a_outputs.zip...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6059b118-c805-4a1f-ba72-09656342a5ff\", \"assignment_1a_outputs.zip\", 10420)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **Text-to-Image** - Imagen 3 (requires special access)\n",
        "2. **Text-to-Video** - Veo 2 (requires special access)\n",
        "3. **Image Analysis** - Works with Gemini API\n",
        "4. **Multi-turn Chat** - Works with Gemini API\n",
        "\n",
        "### References:\n",
        "- https://aistudio.google.com/\n",
        "- https://ai.google.dev/docs\n",
        "- https://www.datacamp.com/blog/janus-pro\n",
        "- https://www.datacamp.com/blog/deepseek-r1\n",
        "\n",
        "---\n",
        "\n",
        "**CMPE 258 - Yashaswini Dinesh - San Jose State University**"
      ],
      "metadata": {
        "id": "conclusion"
      }
    }
  ]
}